{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa40d4ca",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6eda23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33ee77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8588872",
   "metadata": {},
   "source": [
    "# Data Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421bfab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750  images to be resized.\n",
      "750  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "390a846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor_test\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5043c1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750  images to be resized.\n",
      "750  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c86885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock_test\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a155fa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750  images to be resized.\n",
      "750  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8efef79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper_test\"\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65543faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 2250 입니다.\n",
      "x_train shape: (2250, 28, 28, 3)\n",
      "y_train shape: (2250,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=2250):  # 가위바위보 이미지 개수 총합에 주의\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0319dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70328cb1",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d04ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 128)       3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               819456    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 971,395\n",
      "Trainable params: 971,395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_channel_1 = 128\n",
    "n_channel_2 = 128\n",
    "n_dense = 256\n",
    "n_train_epoch = 10\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f7c6b",
   "metadata": {},
   "source": [
    "# 딥러닝 네트워크 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1148192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71/71 [==============================] - 3s 5ms/step - loss: 1.0512 - accuracy: 0.4227\n",
      "Epoch 2/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.7977 - accuracy: 0.6364\n",
      "Epoch 3/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.7529\n",
      "Epoch 4/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8724\n",
      "Epoch 6/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8978\n",
      "Epoch 7/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9191\n",
      "Epoch 8/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9391\n",
      "Epoch 9/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9436\n",
      "Epoch 10/10\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd11879a280>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d3d9f6",
   "metadata": {},
   "source": [
    "# 네트워크 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb0378d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# test data set\n",
    "def load_data2(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper_test/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_test, y_test)=load_data2(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4261c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 571.2882 - accuracy: 0.6267\n",
      "test_loss: 571.2882080078125 \n",
      "test_accuracy: 0.6266666650772095\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b9dcea",
   "metadata": {},
   "source": [
    "# 회고\n",
    "\n",
    "수집한 가위,바위,보 데이터를 딥러닝으로 학습시켜 가위바위보 분류기를 만들었다. 구글의 teachable machine 사이트에서 데이터를 직접 만들어 수집하고 팀원들과 데이터를 공유했다.\n",
    "\n",
    "tf.keras의 Sequential API를 이용하여 LeNet이라는 딥러닝 네트워크를 설계했는데 처음 본 모델이라 이해하는 데 시간이 오래 걸렸지만 팀원들과 질문하며 딥러닝의 흐름을 알게 되었다. 그리고 가위바위보 분류기의 정확도를 높이기 위해서 팀원들과 데이터를 공유하면서 많은 양의 데이터를 어떻게 저장해야 할지 어려움을 겪었다. 검색을 통해 파일을 일괄 변경하는 코드를 알게 되었고 중간에 train, test 변수를 잘못 써서 오류가 날 때마다 train 데이터셋와 test 데이터셋에 대한 이해를 높일 수 있었다.\n",
    "\n",
    "처음 정확도가 나왔을 때는 정확도가 높지 않았다. 그래서 '하이퍼파라미터 조정'과 'train 데이터 갯수 늘리기'를 통해 정확도를 높일 수 있었다. 하이퍼파라미터인 이미지 특징의 갯수와 레이어 갯수를 늘렸더니 정확도를 높아졌다. 그리고 팀원들과 공유 드라이브로 데이터를 교환해서 train 데이터에 추가시켰더니 정확도가 0.6267까지 올라간 것을 확인할 수 있었다.\n",
    "\n",
    "데이터를 직접 만들고 저장해본 적이 없어서 많이 헤맸지만 검색하면서 노드 이외의 방법을 알게 되어서 새로웠다. 또한 팀원들과 데이터를 어떻게 학습시켰는지 공유하고 정확도를 어떻게 더 올릴지 같이 고민하면서 이 프로젝트에 이해가 많이 올랐던 것 같다. 이미지 학습은 처음이어서 이 프로젝트를 통해 이미지 분류의 흐름을 알 수 있었고 또 다른 이미지 데이터를 이용하기 위해서 어떤 모델로 학습해야 할지도 잘  필요성을 느꼈다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
